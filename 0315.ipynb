{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the sensor data of sim that Det3d can accept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the format of the sensor data of *nuscenes*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Det3d read the LiDAR binary files via the following code(line 245-257)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# %load ../nuscenes/nuscenes/utils/data_classes.py\n",
    "# nuScenes dev-kit.\n",
    "# Code written by Oscar Beijbom, 2018.\n",
    "# Licensed under the Creative Commons [see licence.txt]\n",
    "\n",
    "import os.path as osp\n",
    "import struct\n",
    "from abc import ABC, abstractmethod\n",
    "from functools import reduce\n",
    "from typing import Tuple, List, Dict\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib.axes import Axes\n",
    "from pyquaternion import Quaternion\n",
    "\n",
    "from nuscenes.utils.geometry_utils import view_points, transform_matrix\n",
    "\n",
    "\n",
    "class PointCloud(ABC):\n",
    "    \"\"\"\n",
    "    Abstract class for manipulating and viewing point clouds.\n",
    "    Every point cloud (lidar and radar) consists of points where:\n",
    "    - Dimensions 0, 1, 2 represent x, y, z coordinates. These are modified when the point cloud is rotated or translated.\n",
    "    - All other dimensions are optional. Hence these have to be manually modified if the reference frame changes.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, points: np.ndarray):\n",
    "        \"\"\"\n",
    "        Initialize a point cloud and check it has the correct dimensions.\n",
    "        :param points: <np.float: d, n>. d-dimensional input point cloud matrix.\n",
    "        \"\"\"\n",
    "        assert points.shape[0] == self.nbr_dims(), 'Error: Pointcloud points must have format: %d x n' % self.nbr_dims()\n",
    "        self.points = points\n",
    "\n",
    "    @staticmethod\n",
    "    @abstractmethod\n",
    "    def nbr_dims() -> int:\n",
    "        \"\"\"\n",
    "        Returns the number of dimensions.\n",
    "        :return: Number of dimensions.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @classmethod\n",
    "    @abstractmethod\n",
    "    def from_file(cls, file_name: str) -> 'PointCloud':\n",
    "        \"\"\"\n",
    "        Loads point cloud from disk.\n",
    "        :param file_name: Path of the pointcloud file on disk.\n",
    "        :return: PointCloud instance.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @classmethod\n",
    "    def from_file_multisweep(cls,\n",
    "                             nusc: 'NuScenes',\n",
    "                             sample_rec: Dict,\n",
    "                             chan: str,\n",
    "                             ref_chan: str,\n",
    "                             nsweeps: int = 26,\n",
    "                             min_distance: float = 1.0) -> Tuple['PointCloud', np.ndarray]:\n",
    "        \"\"\"\n",
    "        Return a point cloud that aggregates multiple sweeps.\n",
    "        As every sweep is in a different coordinate frame, we need to map the coordinates to a single reference frame.\n",
    "        As every sweep has a different timestamp, we need to account for that in the transformations and timestamps.\n",
    "        :param nusc: A NuScenes instance.\n",
    "        :param sample_rec: The current sample.\n",
    "        :param chan: The radar channel from which we track back n sweeps to aggregate the point cloud.\n",
    "        :param ref_chan: The reference channel of the current sample_rec that the point clouds are mapped to.\n",
    "        :param nsweeps: Number of sweeps to aggregated.\n",
    "        :param min_distance: Distance below which points are discarded.\n",
    "        :return: (all_pc, all_times). The aggregated point cloud and timestamps.\n",
    "        \"\"\"\n",
    "\n",
    "        # Init\n",
    "        points = np.zeros((cls.nbr_dims(), 0))\n",
    "        all_pc = cls(points)\n",
    "        all_times = np.zeros((1, 0))\n",
    "\n",
    "        # Get reference pose and timestamp\n",
    "        ref_sd_token = sample_rec['data'][ref_chan]\n",
    "        ref_sd_rec = nusc.get('sample_data', ref_sd_token)\n",
    "        ref_pose_rec = nusc.get('ego_pose', ref_sd_rec['ego_pose_token'])\n",
    "        ref_cs_rec = nusc.get('calibrated_sensor', ref_sd_rec['calibrated_sensor_token'])\n",
    "        ref_time = 1e-6 * ref_sd_rec['timestamp']\n",
    "\n",
    "        # Homogeneous transform from ego car frame to reference frame\n",
    "        ref_from_car = transform_matrix(ref_cs_rec['translation'], Quaternion(ref_cs_rec['rotation']), inverse=True)\n",
    "\n",
    "        # Homogeneous transformation matrix from global to _current_ ego car frame\n",
    "        car_from_global = transform_matrix(ref_pose_rec['translation'], Quaternion(ref_pose_rec['rotation']),\n",
    "                                           inverse=True)\n",
    "\n",
    "        # Aggregate current and previous sweeps.\n",
    "        sample_data_token = sample_rec['data'][chan]\n",
    "        current_sd_rec = nusc.get('sample_data', sample_data_token)\n",
    "        for _ in range(nsweeps):\n",
    "            # Load up the pointcloud.\n",
    "            current_pc = cls.from_file(osp.join(nusc.dataroot, current_sd_rec['filename']))\n",
    "\n",
    "            # Get past pose.\n",
    "            current_pose_rec = nusc.get('ego_pose', current_sd_rec['ego_pose_token'])\n",
    "            global_from_car = transform_matrix(current_pose_rec['translation'],\n",
    "                                               Quaternion(current_pose_rec['rotation']), inverse=False)\n",
    "\n",
    "            # Homogeneous transformation matrix from sensor coordinate frame to ego car frame.\n",
    "            current_cs_rec = nusc.get('calibrated_sensor', current_sd_rec['calibrated_sensor_token'])\n",
    "            car_from_current = transform_matrix(current_cs_rec['translation'], Quaternion(current_cs_rec['rotation']),\n",
    "                                                inverse=False)\n",
    "\n",
    "            # Fuse four transformation matrices into one and perform transform.\n",
    "            trans_matrix = reduce(np.dot, [ref_from_car, car_from_global, global_from_car, car_from_current])\n",
    "            current_pc.transform(trans_matrix)\n",
    "\n",
    "            # Remove close points and add timevector.\n",
    "            current_pc.remove_close(min_distance)\n",
    "            time_lag = ref_time - 1e-6 * current_sd_rec['timestamp']  # positive difference\n",
    "            times = time_lag * np.ones((1, current_pc.nbr_points()))\n",
    "            all_times = np.hstack((all_times, times))\n",
    "\n",
    "            # Merge with key pc.\n",
    "            all_pc.points = np.hstack((all_pc.points, current_pc.points))\n",
    "\n",
    "            # Abort if there are no previous sweeps.\n",
    "            if current_sd_rec['prev'] == '':\n",
    "                break\n",
    "            else:\n",
    "                current_sd_rec = nusc.get('sample_data', current_sd_rec['prev'])\n",
    "\n",
    "        return all_pc, all_times\n",
    "\n",
    "    def nbr_points(self) -> int:\n",
    "        \"\"\"\n",
    "        Returns the number of points.\n",
    "        :return: Number of points.\n",
    "        \"\"\"\n",
    "        return self.points.shape[1]\n",
    "\n",
    "    def subsample(self, ratio: float) -> None:\n",
    "        \"\"\"\n",
    "        Sub-samples the pointcloud.\n",
    "        :param ratio: Fraction to keep.\n",
    "        \"\"\"\n",
    "        selected_ind = np.random.choice(np.arange(0, self.nbr_points()), size=int(self.nbr_points() * ratio))\n",
    "        self.points = self.points[:, selected_ind]\n",
    "\n",
    "    def remove_close(self, radius: float) -> None:\n",
    "        \"\"\"\n",
    "        Removes point too close within a certain radius from origin.\n",
    "        :param radius: Radius below which points are removed.\n",
    "        \"\"\"\n",
    "\n",
    "        x_filt = np.abs(self.points[0, :]) < radius\n",
    "        y_filt = np.abs(self.points[1, :]) < radius\n",
    "        not_close = np.logical_not(np.logical_and(x_filt, y_filt))\n",
    "        self.points = self.points[:, not_close]\n",
    "\n",
    "    def translate(self, x: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Applies a translation to the point cloud.\n",
    "        :param x: <np.float: 3, 1>. Translation in x, y, z.\n",
    "        \"\"\"\n",
    "        for i in range(3):\n",
    "            self.points[i, :] = self.points[i, :] + x[i]\n",
    "\n",
    "    def rotate(self, rot_matrix: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Applies a rotation.\n",
    "        :param rot_matrix: <np.float: 3, 3>. Rotation matrix.\n",
    "        \"\"\"\n",
    "        self.points[:3, :] = np.dot(rot_matrix, self.points[:3, :])\n",
    "\n",
    "    def transform(self, transf_matrix: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Applies a homogeneous transform.\n",
    "        :param transf_matrix: <np.float: 4, 4>. Homogenous transformation matrix.\n",
    "        \"\"\"\n",
    "        self.points[:3, :] = transf_matrix.dot(np.vstack((self.points[:3, :], np.ones(self.nbr_points()))))[:3, :]\n",
    "\n",
    "    def render_height(self,\n",
    "                      ax: Axes,\n",
    "                      view: np.ndarray = np.eye(4),\n",
    "                      x_lim: Tuple = (-20, 20),\n",
    "                      y_lim: Tuple = (-20, 20),\n",
    "                      marker_size: float = 1) -> None:\n",
    "        \"\"\"\n",
    "        Very simple method that applies a transformation and then scatter plots the points colored by height (z-value).\n",
    "        :param ax: Axes on which to render the points.\n",
    "        :param view: <np.float: n, n>. Defines an arbitrary projection (n <= 4).\n",
    "        :param x_lim: (min <float>, max <float>). x range for plotting.\n",
    "        :param y_lim: (min <float>, max <float>). y range for plotting.\n",
    "        :param marker_size: Marker size.\n",
    "        \"\"\"\n",
    "        self._render_helper(2, ax, view, x_lim, y_lim, marker_size)\n",
    "\n",
    "    def render_intensity(self,\n",
    "                         ax: Axes,\n",
    "                         view: np.ndarray = np.eye(4),\n",
    "                         x_lim: Tuple = (-20, 20),\n",
    "                         y_lim: Tuple = (-20, 20),\n",
    "                         marker_size: float = 1) -> None:\n",
    "        \"\"\"\n",
    "        Very simple method that applies a transformation and then scatter plots the points colored by intensity.\n",
    "        :param ax: Axes on which to render the points.\n",
    "        :param view: <np.float: n, n>. Defines an arbitrary projection (n <= 4).\n",
    "        :param x_lim: (min <float>, max <float>).\n",
    "        :param y_lim: (min <float>, max <float>).\n",
    "        :param marker_size: Marker size.\n",
    "        \"\"\"\n",
    "        self._render_helper(3, ax, view, x_lim, y_lim, marker_size)\n",
    "\n",
    "    def _render_helper(self,\n",
    "                       color_channel: int,\n",
    "                       ax: Axes,\n",
    "                       view: np.ndarray,\n",
    "                       x_lim: Tuple,\n",
    "                       y_lim: Tuple,\n",
    "                       marker_size: float) -> None:\n",
    "        \"\"\"\n",
    "        Helper function for rendering.\n",
    "        :param color_channel: Point channel to use as color.\n",
    "        :param ax: Axes on which to render the points.\n",
    "        :param view: <np.float: n, n>. Defines an arbitrary projection (n <= 4).\n",
    "        :param x_lim: (min <float>, max <float>).\n",
    "        :param y_lim: (min <float>, max <float>).\n",
    "        :param marker_size: Marker size.\n",
    "        \"\"\"\n",
    "        points = view_points(self.points[:3, :], view, normalize=False)\n",
    "        ax.scatter(points[0, :], points[1, :], c=self.points[color_channel, :], s=marker_size)\n",
    "        ax.set_xlim(x_lim[0], x_lim[1])\n",
    "        ax.set_ylim(y_lim[0], y_lim[1])\n",
    "\n",
    "\n",
    "class LidarPointCloud(PointCloud):\n",
    "\n",
    "    @staticmethod\n",
    "    def nbr_dims() -> int:\n",
    "        \"\"\"\n",
    "        Returns the number of dimensions.\n",
    "        :return: Number of dimensions.\n",
    "        \"\"\"\n",
    "        return 4\n",
    "\n",
    "    @classmethod\n",
    "    def from_file(cls, file_name: str) -> 'LidarPointCloud':\n",
    "        \"\"\"\n",
    "        Loads LIDAR data from binary numpy format. Data is stored as (x, y, z, intensity, ring index).\n",
    "        :param file_name: Path of the pointcloud file on disk.\n",
    "        :return: LidarPointCloud instance (x, y, z, intensity).\n",
    "        \"\"\"\n",
    "\n",
    "        assert file_name.endswith('.bin'), 'Unsupported filetype {}'.format(file_name)\n",
    "\n",
    "        scan = np.fromfile(file_name, dtype=np.float32)\n",
    "        points = scan.reshape((-1, 5))[:, :cls.nbr_dims()]\n",
    "        return cls(points.T)\n",
    "\n",
    "\n",
    "class RadarPointCloud(PointCloud):\n",
    "\n",
    "    # Class-level settings for radar pointclouds, see from_file().\n",
    "    invalid_states = [0]  # type: List[int]\n",
    "    dynprop_states = range(7)  # type: List[int] # Use [0, 2, 6] for moving objects only.\n",
    "    ambig_states = [3]  # type: List[int]\n",
    "\n",
    "    @staticmethod\n",
    "    def nbr_dims() -> int:\n",
    "        \"\"\"\n",
    "        Returns the number of dimensions.\n",
    "        :return: Number of dimensions.\n",
    "        \"\"\"\n",
    "        return 18\n",
    "\n",
    "    @classmethod\n",
    "    def from_file(cls,\n",
    "                  file_name: str,\n",
    "                  invalid_states: List[int] = None,\n",
    "                  dynprop_states: List[int] = None,\n",
    "                  ambig_states: List[int] = None) -> 'RadarPointCloud':\n",
    "        \"\"\"\n",
    "        Loads RADAR data from a Point Cloud Data file. See details below.\n",
    "        :param file_name: The path of the pointcloud file.\n",
    "        :param invalid_states: Radar states to be kept. See details below.\n",
    "        :param dynprop_states: Radar states to be kept. Use [0, 2, 6] for moving objects only. See details below.\n",
    "        :param ambig_states: Radar states to be kept. See details below.\n",
    "        To keep all radar returns, set each state filter to range(18).\n",
    "        :return: <np.float: d, n>. Point cloud matrix with d dimensions and n points.\n",
    "\n",
    "        Example of the header fields:\n",
    "        # .PCD v0.7 - Point Cloud Data file format\n",
    "        VERSION 0.7\n",
    "        FIELDS x y z dyn_prop id rcs vx vy vx_comp vy_comp is_quality_valid ambig_state x_rms y_rms invalid_state pdh0 vx_rms vy_rms\n",
    "        SIZE 4 4 4 1 2 4 4 4 4 4 1 1 1 1 1 1 1 1\n",
    "        TYPE F F F I I F F F F F I I I I I I I I\n",
    "        COUNT 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
    "        WIDTH 125\n",
    "        HEIGHT 1\n",
    "        VIEWPOINT 0 0 0 1 0 0 0\n",
    "        POINTS 125\n",
    "        DATA binary\n",
    "\n",
    "        Below some of the fields are explained in more detail:\n",
    "\n",
    "        x is front, y is left\n",
    "\n",
    "        vx, vy are the velocities in m/s.\n",
    "        vx_comp, vy_comp are the velocities in m/s compensated by the ego motion.\n",
    "        We recommend using the compensated velocities.\n",
    "\n",
    "        invalid_state: state of Cluster validity state.\n",
    "        (Invalid states)\n",
    "        0x01\tinvalid due to low RCS\n",
    "        0x02\tinvalid due to near-field artefact\n",
    "        0x03\tinvalid far range cluster because not confirmed in near range\n",
    "        0x05\treserved\n",
    "        0x06\tinvalid cluster due to high mirror probability\n",
    "        0x07\tInvalid cluster because outside sensor field of view\n",
    "        0x0d\treserved\n",
    "        0x0e\tinvalid cluster because it is a harmonics\n",
    "        (Valid states)\n",
    "        0x00\tvalid\n",
    "        0x04\tvalid cluster with low RCS\n",
    "        0x08\tvalid cluster with azimuth correction due to elevation\n",
    "        0x09\tvalid cluster with high child probability\n",
    "        0x0a\tvalid cluster with high probability of being a 50 deg artefact\n",
    "        0x0b\tvalid cluster but no local maximum\n",
    "        0x0c\tvalid cluster with high artefact probability\n",
    "        0x0f\tvalid cluster with above 95m in near range\n",
    "        0x10\tvalid cluster with high multi-target probability\n",
    "        0x11\tvalid cluster with suspicious angle\n",
    "\n",
    "        dynProp: Dynamic property of cluster to indicate if is moving or not.\n",
    "        0: moving\n",
    "        1: stationary\n",
    "        2: oncoming\n",
    "        3: stationary candidate\n",
    "        4: unknown\n",
    "        5: crossing stationary\n",
    "        6: crossing moving\n",
    "        7: stopped\n",
    "\n",
    "        ambig_state: State of Doppler (radial velocity) ambiguity solution.\n",
    "        0: invalid\n",
    "        1: ambiguous\n",
    "        2: staggered ramp\n",
    "        3: unambiguous\n",
    "        4: stationary candidates\n",
    "\n",
    "        pdh0: False alarm probability of cluster (i.e. probability of being an artefact caused by multipath or similar).\n",
    "        0: invalid\n",
    "        1: <25%\n",
    "        2: 50%\n",
    "        3: 75%\n",
    "        4: 90%\n",
    "        5: 99%\n",
    "        6: 99.9%\n",
    "        7: <=100%\n",
    "        \"\"\"\n",
    "\n",
    "        assert file_name.endswith('.pcd'), 'Unsupported filetype {}'.format(file_name)\n",
    "\n",
    "        meta = []\n",
    "        with open(file_name, 'rb') as f:\n",
    "            for line in f:\n",
    "                line = line.strip().decode('utf-8')\n",
    "                meta.append(line)\n",
    "                if line.startswith('DATA'):\n",
    "                    break\n",
    "\n",
    "            data_binary = f.read()\n",
    "\n",
    "        # Get the header rows and check if they appear as expected.\n",
    "        assert meta[0].startswith('#'), 'First line must be comment'\n",
    "        assert meta[1].startswith('VERSION'), 'Second line must be VERSION'\n",
    "        sizes = meta[3].split(' ')[1:]\n",
    "        types = meta[4].split(' ')[1:]\n",
    "        counts = meta[5].split(' ')[1:]\n",
    "        width = int(meta[6].split(' ')[1])\n",
    "        height = int(meta[7].split(' ')[1])\n",
    "        data = meta[10].split(' ')[1]\n",
    "        feature_count = len(types)\n",
    "        assert width > 0\n",
    "        assert len([c for c in counts if c != c]) == 0, 'Error: COUNT not supported!'\n",
    "        assert height == 1, 'Error: height != 0 not supported!'\n",
    "        assert data == 'binary'\n",
    "\n",
    "        # Lookup table for how to decode the binaries.\n",
    "        unpacking_lut = {'F': {2: 'e', 4: 'f', 8: 'd'},\n",
    "                         'I': {1: 'b', 2: 'h', 4: 'i', 8: 'q'},\n",
    "                         'U': {1: 'B', 2: 'H', 4: 'I', 8: 'Q'}}\n",
    "        types_str = ''.join([unpacking_lut[t][int(s)] for t, s in zip(types, sizes)])\n",
    "\n",
    "        # Decode each point.\n",
    "        offset = 0\n",
    "        point_count = width\n",
    "        points = []\n",
    "        for i in range(point_count):\n",
    "            point = []\n",
    "            for p in range(feature_count):\n",
    "                start_p = offset\n",
    "                end_p = start_p + int(sizes[p])\n",
    "                assert end_p < len(data_binary)\n",
    "                point_p = struct.unpack(types_str[p], data_binary[start_p:end_p])[0]\n",
    "                point.append(point_p)\n",
    "                offset = end_p\n",
    "            points.append(point)\n",
    "\n",
    "        # A NaN in the first point indicates an empty pointcloud.\n",
    "        point = np.array(points[0])\n",
    "        if np.any(np.isnan(point)):\n",
    "            return cls(np.zeros((feature_count, 0)))\n",
    "\n",
    "        # Convert to numpy matrix.\n",
    "        points = np.array(points).transpose()\n",
    "\n",
    "        # If no parameters are provided, use default settings.\n",
    "        invalid_states = cls.invalid_states if invalid_states is None else invalid_states\n",
    "        dynprop_states = cls.dynprop_states if dynprop_states is None else dynprop_states\n",
    "        ambig_states = cls.ambig_states if ambig_states is None else ambig_states\n",
    "\n",
    "        # Filter points with an invalid state.\n",
    "        valid = [p in invalid_states for p in points[-4, :]]\n",
    "        points = points[:, valid]\n",
    "\n",
    "        # Filter by dynProp.\n",
    "        valid = [p in dynprop_states for p in points[3, :]]\n",
    "        points = points[:, valid]\n",
    "\n",
    "        # Filter by ambig_state.\n",
    "        valid = [p in ambig_states for p in points[11, :]]\n",
    "        points = points[:, valid]\n",
    "\n",
    "        return cls(points)\n",
    "\n",
    "\n",
    "class Box:\n",
    "    \"\"\" Simple data class representing a 3d box including, label, score and velocity. \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 center: List[float],\n",
    "                 size: List[float],\n",
    "                 orientation: Quaternion,\n",
    "                 label: int = np.nan,\n",
    "                 score: float = np.nan,\n",
    "                 velocity: Tuple = (np.nan, np.nan, np.nan),\n",
    "                 name: str = None,\n",
    "                 token: str = None):\n",
    "        \"\"\"\n",
    "        :param center: Center of box given as x, y, z.\n",
    "        :param size: Size of box in width, length, height.\n",
    "        :param orientation: Box orientation.\n",
    "        :param label: Integer label, optional.\n",
    "        :param score: Classification score, optional.\n",
    "        :param velocity: Box velocity in x, y, z direction.\n",
    "        :param name: Box name, optional. Can be used e.g. for denote category name.\n",
    "        :param token: Unique string identifier from DB.\n",
    "        \"\"\"\n",
    "        assert not np.any(np.isnan(center))\n",
    "        assert not np.any(np.isnan(size))\n",
    "        assert len(center) == 3\n",
    "        assert len(size) == 3\n",
    "        assert type(orientation) == Quaternion\n",
    "\n",
    "        self.center = np.array(center)\n",
    "        self.wlh = np.array(size)\n",
    "        self.orientation = orientation\n",
    "        self.label = int(label) if not np.isnan(label) else label\n",
    "        self.score = float(score) if not np.isnan(score) else score\n",
    "        self.velocity = np.array(velocity)\n",
    "        self.name = name\n",
    "        self.token = token\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        center = np.allclose(self.center, other.center)\n",
    "        wlh = np.allclose(self.wlh, other.wlh)\n",
    "        orientation = np.allclose(self.orientation.elements, other.orientation.elements)\n",
    "        label = (self.label == other.label) or (np.isnan(self.label) and np.isnan(other.label))\n",
    "        score = (self.score == other.score) or (np.isnan(self.score) and np.isnan(other.score))\n",
    "        vel = (np.allclose(self.velocity, other.velocity) or\n",
    "               (np.all(np.isnan(self.velocity)) and np.all(np.isnan(other.velocity))))\n",
    "\n",
    "        return center and wlh and orientation and label and score and vel\n",
    "\n",
    "    def __repr__(self):\n",
    "        repr_str = 'label: {}, score: {:.2f}, xyz: [{:.2f}, {:.2f}, {:.2f}], wlh: [{:.2f}, {:.2f}, {:.2f}], ' \\\n",
    "                   'rot axis: [{:.2f}, {:.2f}, {:.2f}], ang(degrees): {:.2f}, ang(rad): {:.2f}, ' \\\n",
    "                   'vel: {:.2f}, {:.2f}, {:.2f}, name: {}, token: {}'\n",
    "\n",
    "        return repr_str.format(self.label, self.score, self.center[0], self.center[1], self.center[2], self.wlh[0],\n",
    "                               self.wlh[1], self.wlh[2], self.orientation.axis[0], self.orientation.axis[1],\n",
    "                               self.orientation.axis[2], self.orientation.degrees, self.orientation.radians,\n",
    "                               self.velocity[0], self.velocity[1], self.velocity[2], self.name, self.token)\n",
    "\n",
    "    @property\n",
    "    def rotation_matrix(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Return a rotation matrix.\n",
    "        :return: <np.float: 3, 3>. The box's rotation matrix.\n",
    "        \"\"\"\n",
    "        return self.orientation.rotation_matrix\n",
    "\n",
    "    def translate(self, x: np.ndarray) -> None:\n",
    "        \"\"\"\n",
    "        Applies a translation.\n",
    "        :param x: <np.float: 3, 1>. Translation in x, y, z direction.\n",
    "        \"\"\"\n",
    "        self.center += x\n",
    "\n",
    "    def rotate(self, quaternion: Quaternion) -> None:\n",
    "        \"\"\"\n",
    "        Rotates box.\n",
    "        :param quaternion: Rotation to apply.\n",
    "        \"\"\"\n",
    "        self.center = np.dot(quaternion.rotation_matrix, self.center)\n",
    "        self.orientation = quaternion * self.orientation\n",
    "        self.velocity = np.dot(quaternion.rotation_matrix, self.velocity)\n",
    "\n",
    "    def corners(self, wlh_factor: float = 1.0) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Returns the bounding box corners.\n",
    "        :param wlh_factor: Multiply w, l, h by a factor to scale the box.\n",
    "        :return: <np.float: 3, 8>. First four corners are the ones facing forward.\n",
    "            The last four are the ones facing backwards.\n",
    "        \"\"\"\n",
    "        w, l, h = self.wlh * wlh_factor\n",
    "\n",
    "        # 3D bounding box corners. (Convention: x points forward, y to the left, z up.)\n",
    "        x_corners = l / 2 * np.array([1,  1,  1,  1, -1, -1, -1, -1])\n",
    "        y_corners = w / 2 * np.array([1, -1, -1,  1,  1, -1, -1,  1])\n",
    "        z_corners = h / 2 * np.array([1,  1, -1, -1,  1,  1, -1, -1])\n",
    "        corners = np.vstack((x_corners, y_corners, z_corners))\n",
    "\n",
    "        # Rotate\n",
    "        corners = np.dot(self.orientation.rotation_matrix, corners)\n",
    "\n",
    "        # Translate\n",
    "        x, y, z = self.center\n",
    "        corners[0, :] = corners[0, :] + x\n",
    "        corners[1, :] = corners[1, :] + y\n",
    "        corners[2, :] = corners[2, :] + z\n",
    "\n",
    "        return corners\n",
    "\n",
    "    def bottom_corners(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Returns the four bottom corners.\n",
    "        :return: <np.float: 3, 4>. Bottom corners. First two face forward, last two face backwards.\n",
    "        \"\"\"\n",
    "        return self.corners()[:, [2, 3, 7, 6]]\n",
    "\n",
    "    def render(self,\n",
    "               axis: Axes,\n",
    "               view: np.ndarray = np.eye(3),\n",
    "               normalize: bool = False,\n",
    "               colors: Tuple = ('b', 'r', 'k'),\n",
    "               linewidth: float = 2):\n",
    "        \"\"\"\n",
    "        Renders the box in the provided Matplotlib axis.\n",
    "        :param axis: Axis onto which the box should be drawn.\n",
    "        :param view: <np.array: 3, 3>. Define a projection in needed (e.g. for drawing projection in an image).\n",
    "        :param normalize: Whether to normalize the remaining coordinate.\n",
    "        :param colors: (<Matplotlib.colors>: 3). Valid Matplotlib colors (<str> or normalized RGB tuple) for front,\n",
    "            back and sides.\n",
    "        :param linewidth: Width in pixel of the box sides.\n",
    "        \"\"\"\n",
    "        corners = view_points(self.corners(), view, normalize=normalize)[:2, :]\n",
    "\n",
    "        def draw_rect(selected_corners, color):\n",
    "            prev = selected_corners[-1]\n",
    "            for corner in selected_corners:\n",
    "                axis.plot([prev[0], corner[0]], [prev[1], corner[1]], color=color, linewidth=linewidth)\n",
    "                prev = corner\n",
    "\n",
    "        # Draw the sides\n",
    "        for i in range(4):\n",
    "            axis.plot([corners.T[i][0], corners.T[i + 4][0]],\n",
    "                      [corners.T[i][1], corners.T[i + 4][1]],\n",
    "                      color=colors[2], linewidth=linewidth)\n",
    "\n",
    "        # Draw front (first 4 corners) and rear (last 4 corners) rectangles(3d)/lines(2d)\n",
    "        draw_rect(corners.T[:4], colors[0])\n",
    "        draw_rect(corners.T[4:], colors[1])\n",
    "\n",
    "        # Draw line indicating the front\n",
    "        center_bottom_forward = np.mean(corners.T[2:4], axis=0)\n",
    "        center_bottom = np.mean(corners.T[[2, 3, 7, 6]], axis=0)\n",
    "        axis.plot([center_bottom[0], center_bottom_forward[0]],\n",
    "                  [center_bottom[1], center_bottom_forward[1]],\n",
    "                  color=colors[0], linewidth=linewidth)\n",
    "\n",
    "    def render_cv2(self,\n",
    "                   im: np.ndarray,\n",
    "                   view: np.ndarray = np.eye(3),\n",
    "                   normalize: bool = False,\n",
    "                   colors: Tuple = ((0, 0, 255), (255, 0, 0), (155, 155, 155)),\n",
    "                   linewidth: int = 2) -> None:\n",
    "        \"\"\"\n",
    "        Renders box using OpenCV2.\n",
    "        :param im: <np.array: width, height, 3>. Image array. Channels are in BGR order.\n",
    "        :param view: <np.array: 3, 3>. Define a projection if needed (e.g. for drawing projection in an image).\n",
    "        :param normalize: Whether to normalize the remaining coordinate.\n",
    "        :param colors: ((R, G, B), (R, G, B), (R, G, B)). Colors for front, side & rear.\n",
    "        :param linewidth: Linewidth for plot.\n",
    "        \"\"\"\n",
    "        corners = view_points(self.corners(), view, normalize=normalize)[:2, :]\n",
    "\n",
    "        def draw_rect(selected_corners, color):\n",
    "            prev = selected_corners[-1]\n",
    "            for corner in selected_corners:\n",
    "                cv2.line(im,\n",
    "                         (int(prev[0]), int(prev[1])),\n",
    "                         (int(corner[0]), int(corner[1])),\n",
    "                         color, linewidth)\n",
    "                prev = corner\n",
    "\n",
    "        # Draw the sides\n",
    "        for i in range(4):\n",
    "            cv2.line(im,\n",
    "                     (int(corners.T[i][0]), int(corners.T[i][1])),\n",
    "                     (int(corners.T[i + 4][0]), int(corners.T[i + 4][1])),\n",
    "                     colors[2][::-1], linewidth)\n",
    "\n",
    "        # Draw front (first 4 corners) and rear (last 4 corners) rectangles(3d)/lines(2d)\n",
    "        draw_rect(corners.T[:4], colors[0][::-1])\n",
    "        draw_rect(corners.T[4:], colors[1][::-1])\n",
    "\n",
    "        # Draw line indicating the front\n",
    "        center_bottom_forward = np.mean(corners.T[2:4], axis=0)\n",
    "        center_bottom = np.mean(corners.T[[2, 3, 7, 6]], axis=0)\n",
    "        cv2.line(im,\n",
    "                 (int(center_bottom[0]), int(center_bottom[1])),\n",
    "                 (int(center_bottom_forward[0]), int(center_bottom_forward[1])),\n",
    "                 colors[0][::-1], linewidth)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the nuscenes LiDAR data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.13254929e+00  1.20474165e-02 -1.85774922e+00  3.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [-3.31115246e+00  1.39069343e-02 -1.86039686e+00  2.00000000e+00\n",
      "   1.00000000e+00]\n",
      " [-3.50170469e+00  1.52497254e-02 -1.86191487e+00  2.00000000e+00\n",
      "   2.00000000e+00]\n",
      " [-3.73735046e+00  1.75725669e-02 -1.87643194e+00  1.00000000e+00\n",
      "   3.00000000e+00]\n",
      " [-3.98058009e+00  2.01833453e-02 -1.88414872e+00  2.00000000e+00\n",
      "   4.00000000e+00]\n",
      " [-4.26623058e+00  2.23737992e-02 -1.89943671e+00  1.00000000e+00\n",
      "   5.00000000e+00]\n",
      " [-4.53609037e+00  2.53399163e-02 -1.89471471e+00  2.00000000e+00\n",
      "   6.00000000e+00]\n",
      " [-4.87540102e+00  2.89112106e-02 -1.90378296e+00  1.00000000e+00\n",
      "   7.00000000e+00]\n",
      " [-5.25093842e+00  3.21028456e-02 -1.91117382e+00  2.00000000e+00\n",
      "   8.00000000e+00]\n",
      " [-5.67661619e+00  3.66844051e-02 -1.91810095e+00  4.00000000e+00\n",
      "   9.00000000e+00]\n",
      " [-6.17038012e+00  4.19779122e-02 -1.92541969e+00  2.00000000e+00\n",
      "   1.00000000e+01]\n",
      " [-6.73443031e+00  4.70140949e-02 -1.93106425e+00  1.50000000e+01\n",
      "   1.10000000e+01]\n",
      " [-7.44106007e+00  5.45222089e-02 -1.94795191e+00  5.00000000e+00\n",
      "   1.20000000e+01]\n",
      " [-7.53514767e+00  5.65587990e-02 -1.78538966e+00  5.10000000e+01\n",
      "   1.30000000e+01]\n",
      " [-8.18687725e+00  6.43228590e-02 -1.74015081e+00  5.20000000e+01\n",
      "   1.40000000e+01]\n",
      " [-9.25485134e+00  7.59668276e-02 -1.74367738e+00  5.00000000e+00\n",
      "   1.50000000e+01]\n",
      " [-1.02386494e+01  4.11243737e-02 -1.68206561e+00  4.50000000e+01\n",
      "   1.60000000e+01]\n",
      " [-1.16573639e+01  4.88395393e-02 -1.63823223e+00  4.00000000e+00\n",
      "   1.70000000e+01]\n",
      " [ 3.29309405e-05  9.94562652e-05 -3.00350603e-05  1.17000000e+02\n",
      "   1.80000000e+01]\n",
      " [-1.32482996e+01  6.47665784e-02 -1.23588705e+00  3.50000000e+01\n",
      "   1.90000000e+01]\n",
      " [-1.29262419e+01  6.54395297e-02 -9.03776944e-01  8.40000000e+01\n",
      "   2.00000000e+01]\n",
      " [-1.35370884e+01  7.32521489e-02 -6.31164670e-01  5.00000000e+00\n",
      "   2.10000000e+01]\n",
      " [-2.33233070e+01  1.34413406e-01 -5.41247427e-01  8.00000000e+00\n",
      "   2.20000000e+01]\n",
      " [ 3.29309405e-05  9.94562652e-05 -3.00350603e-05  2.20000000e+01\n",
      "   2.30000000e+01]\n",
      " [ 3.29309405e-05  9.94562652e-05 -3.00350603e-05  6.30000000e+01\n",
      "   2.40000000e+01]\n",
      " [-1.70510845e+01  1.13159768e-01  7.95356929e-01  8.00000000e+00\n",
      "   2.50000000e+01]\n",
      " [-1.70160122e+01  1.15949683e-01  1.19008577e+00  2.60000000e+01\n",
      "   2.60000000e+01]\n",
      " [ 3.29309405e-05  9.94562652e-05 -3.00350603e-05  4.60000000e+01\n",
      "   2.70000000e+01]\n",
      " [-1.52138681e+01  1.14366271e-01  1.77935660e+00  1.40000000e+01\n",
      "   2.80000000e+01]\n",
      " [ 3.29309405e-05  9.94562652e-05 -3.00350603e-05  1.11000000e+02\n",
      "   2.90000000e+01]\n",
      " [ 3.29309405e-05  9.94562652e-05 -3.00350603e-05  8.10000000e+01\n",
      "   3.00000000e+01]\n",
      " [-1.23973742e+01  1.03986107e-01  2.33599782e+00  4.00000000e+00\n",
      "   3.10000000e+01]\n",
      " [-3.12897754e+00  3.00834216e-02 -1.85570765e+00  3.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [-3.31270099e+00  3.29133384e-02 -1.86138284e+00  2.00000000e+00\n",
      "   1.00000000e+00]\n",
      " [-3.52274084e+00  3.56198773e-02 -1.87318373e+00  2.00000000e+00\n",
      "   2.00000000e+00]\n",
      " [-3.74432111e+00  3.91755104e-02 -1.88002193e+00  1.00000000e+00\n",
      "   3.00000000e+00]\n",
      " [-3.97675538e+00  4.30230722e-02 -1.88244152e+00  2.00000000e+00\n",
      "   4.00000000e+00]\n",
      " [-4.25500822e+00  4.67860885e-02 -1.89455950e+00  1.00000000e+00\n",
      "   5.00000000e+00]\n",
      " [-4.53040886e+00  5.14357574e-02 -1.89240074e+00  2.00000000e+00\n",
      "   6.00000000e+00]\n",
      " [-4.86768723e+00  5.69574162e-02 -1.90087056e+00  1.00000000e+00\n",
      "   7.00000000e+00]\n",
      " [-5.25064754e+00  6.23380877e-02 -1.91117537e+00  2.00000000e+00\n",
      "   8.00000000e+00]\n",
      " [-5.66868925e+00  6.92325234e-02 -1.91554499e+00  4.00000000e+00\n",
      "   9.00000000e+00]\n",
      " [-6.17772913e+00  7.76140466e-02 -1.92780364e+00  2.00000000e+00\n",
      "   1.00000000e+01]\n",
      " [-6.73216343e+00  8.57758671e-02 -1.93051434e+00  1.60000000e+01\n",
      "   1.10000000e+01]\n",
      " [-7.43282127e+00  9.72611606e-02 -1.94592869e+00  6.00000000e+00\n",
      "   1.20000000e+01]\n",
      " [-7.55999517e+00  1.00255668e-01 -1.79138803e+00  5.10000000e+01\n",
      "   1.30000000e+01]\n",
      " [-8.18633747e+00  1.11420974e-01 -1.74015629e+00  4.80000000e+01\n",
      "   1.40000000e+01]\n",
      " [-9.23455811e+00  1.28920361e-01 -1.73998189e+00  4.00000000e+00\n",
      "   1.50000000e+01]\n",
      " [-1.02145481e+01  9.98724997e-02 -1.67817640e+00  4.90000000e+01\n",
      "   1.60000000e+01]\n",
      " [-1.16529083e+01  1.15958832e-01 -1.63767672e+00  4.00000000e+00\n",
      "   1.70000000e+01]\n",
      " [-1.33128443e+01  1.37160242e-01 -1.55442524e+00  3.00000000e+01\n",
      "   1.80000000e+01]\n",
      " [-1.31003542e+01  1.39486983e-01 -1.22214472e+00  4.50000000e+01\n",
      "   1.90000000e+01]\n",
      " [-1.30253754e+01  1.40949279e-01 -9.10755277e-01  9.00000000e+01\n",
      "   2.00000000e+01]\n",
      " [ 3.29309405e-05  9.94562652e-05 -3.00350603e-05  1.44000000e+02\n",
      "   2.10000000e+01]\n",
      " [ 3.29309405e-05  9.94562652e-05 -3.00350603e-05  3.50000000e+01\n",
      "   2.20000000e+01]\n",
      " [-1.70487862e+01  1.99414492e-01  1.74459012e-04  2.80000000e+01\n",
      "   2.30000000e+01]\n",
      " [-1.70081654e+01  2.04909265e-01  3.95083547e-01  2.70000000e+01\n",
      "   2.40000000e+01]\n",
      " [-1.37819195e+01  1.70915142e-01  6.42896414e-01  1.60000000e+01\n",
      "   2.50000000e+01]\n",
      " [-1.36076593e+01  1.71113178e-01  9.51751709e-01  2.30000000e+01\n",
      "   2.60000000e+01]\n",
      " [-1.36415691e+01  1.76321805e-01  1.27294028e+00  1.60000000e+01\n",
      "   2.70000000e+01]\n",
      " [-1.70403080e+01  2.26207644e-01  1.99309087e+00  1.30000000e+01\n",
      "   2.80000000e+01]\n",
      " [-1.36030369e+01  1.82920560e-01  1.91209090e+00  4.10000000e+01\n",
      "   2.90000000e+01]\n",
      " [-1.32964354e+01  1.83535203e-01  2.18486881e+00  2.10000000e+01\n",
      "   3.00000000e+01]\n",
      " [ 3.29309405e-05  9.94562652e-05 -3.00350603e-05  2.40000000e+01\n",
      "   3.10000000e+01]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "scan = \\\n",
    "np.fromfile\\\n",
    "('../Det3D/data/datasets/samples/LIDAR_TOP/n015-2018-11-21-19-38-26+0800__LIDAR_TOP__1542801005947122.pcd.bin',\\\n",
    "                   dtype='float32')\n",
    "points = scan.reshape((-1, 5))\n",
    "print(points[:64])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**nuscenes** dataset has four subfolder: \n",
    "- [ ] maps: the maps of the areas where the data was collected.\n",
    "- [x] samples: the sensor data of the **keyframes**(sampled at 2Hz, well annotated)\n",
    "- [x] sweeps: the sensor data of the **intermediate frames**(no annotation)\n",
    "- [x] v1.0-[version]: the annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read one of the LiDAR-TOP keyframe data. Eeah point has five attributes. **I guess** they represent **x, y, z, reflectivity and beam**, respectively. (*The LiDAR of nuscenes has 32 beams*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The beam data is deicarded in Det3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the nuscenes format 3D millimeter-wave holographic image data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 3D millimeter-wave holograhic image data is structured. Compare to point cloud data, We do not have to store the space coordinates explicitly. If we save the attributes of the points in order, we can infer their space coordinates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the holographic image binary file was created via Matlab in the **width-height-depth** order. Each point has 2 attributes: **magnitude(reflectivity) and angle**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.01139254  0.37834758]\n",
      " [ 0.01401756  0.1257427 ]\n",
      " [ 0.0173781  -0.21380393]\n",
      " [ 0.02060556 -0.6300102 ]\n",
      " [ 0.02252664 -1.1263735 ]\n",
      " [ 0.02121327 -1.7014707 ]\n",
      " [ 0.01525385 -2.338461  ]\n",
      " [ 0.00515413 -3.0519855 ]\n",
      " [ 0.00669782 -0.4518677 ]\n",
      " [ 0.01692241 -1.1727124 ]\n",
      " [ 0.01641835  0.3876011 ]\n",
      " [ 0.02383335 -0.35012183]\n",
      " [ 0.02753106 -1.153947  ]\n",
      " [ 0.02786709 -2.0537798 ]\n",
      " [ 0.02743384 -3.0667527 ]\n",
      " [ 0.02934008  2.1753297 ]\n",
      " [ 0.03352945  1.2464168 ]\n",
      " [ 0.03749603  0.45727292]\n",
      " [ 0.03925562 -0.23911363]\n",
      " [ 0.03773948 -0.8911138 ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "scan = np.fromfile('data/img_mag_ang_whd.bin',dtype='float32')\n",
    "height = 400\n",
    "width = 190\n",
    "depth = 200\n",
    "count = height*width*depth\n",
    "assert len(scan)/2 == count, 'points number mismatch' \n",
    "scan.resize((count, 2))\n",
    "print(scan[190:210])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infer the space coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 15200000, 3)\n",
      "[[ 0.00000000e+00  0.00000000e+00  1.90000000e+02  1.13925366e-02\n",
      "   3.78347576e-01]\n",
      " [ 0.00000000e+00  0.00000000e+00  1.91000000e+02  1.40175624e-02\n",
      "   1.25742704e-01]\n",
      " [ 0.00000000e+00  0.00000000e+00  1.92000000e+02  1.73781011e-02\n",
      "  -2.13803932e-01]\n",
      " [ 0.00000000e+00  0.00000000e+00  1.93000000e+02  2.06055567e-02\n",
      "  -6.30010188e-01]\n",
      " [ 0.00000000e+00  0.00000000e+00  1.94000000e+02  2.25266442e-02\n",
      "  -1.12637353e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  1.95000000e+02  2.12132651e-02\n",
      "  -1.70147073e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  1.96000000e+02  1.52538512e-02\n",
      "  -2.33846092e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  1.97000000e+02  5.15413377e-03\n",
      "  -3.05198550e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  1.98000000e+02  6.69782097e-03\n",
      "  -4.51867700e-01]\n",
      " [ 0.00000000e+00  0.00000000e+00  1.99000000e+02  1.69224143e-02\n",
      "  -1.17271245e+00]\n",
      " [ 0.00000000e+00  1.00000000e+00  0.00000000e+00  1.64183471e-02\n",
      "   3.87601107e-01]\n",
      " [ 0.00000000e+00  1.00000000e+00  1.00000000e+00  2.38333549e-02\n",
      "  -3.50121826e-01]\n",
      " [ 0.00000000e+00  1.00000000e+00  2.00000000e+00  2.75310576e-02\n",
      "  -1.15394700e+00]\n",
      " [ 0.00000000e+00  1.00000000e+00  3.00000000e+00  2.78670918e-02\n",
      "  -2.05377984e+00]\n",
      " [ 0.00000000e+00  1.00000000e+00  4.00000000e+00  2.74338387e-02\n",
      "  -3.06675267e+00]\n",
      " [ 0.00000000e+00  1.00000000e+00  5.00000000e+00  2.93400772e-02\n",
      "   2.17532969e+00]\n",
      " [ 0.00000000e+00  1.00000000e+00  6.00000000e+00  3.35294455e-02\n",
      "   1.24641681e+00]\n",
      " [ 0.00000000e+00  1.00000000e+00  7.00000000e+00  3.74960303e-02\n",
      "   4.57272917e-01]\n",
      " [ 0.00000000e+00  1.00000000e+00  8.00000000e+00  3.92556190e-02\n",
      "  -2.39113629e-01]\n",
      " [ 0.00000000e+00  1.00000000e+00  9.00000000e+00  3.77394818e-02\n",
      "  -8.91113818e-01]]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(height)\n",
    "b = np.arange(width)\n",
    "c = np.arange(depth)\n",
    "d,e,f = np.meshgrid(a,b,c)\n",
    "index = np.dstack((e.ravel(),d.ravel(),f.ravel()))\n",
    "print(index.shape)\n",
    "index.resize(count,3)\n",
    "data = np.concatenate((index,scan),axis=1)\n",
    "print(data[190:210])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
